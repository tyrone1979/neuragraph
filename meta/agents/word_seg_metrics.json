{
  "name": "Word Segmentation Metrics Calculation",
  "type": "PGM",
  "inputs": [
    "predicted",
    "expected"
  ],
  "outputs": {
    "name": "output",
    "type": "dict"
  },
  "process": "\"\"\"\n评估两个分词字符串的差异\n输入格式：'| word1 | word2 | word3 |'\n\"\"\"\nreal_str = state['expected']\npredicted_str = state['predicted']\n# 1. 清理和解析字符串\ndef parse_segmentation_string(seg_str):\n    # 移除首尾的'|'和空格，然后分割\n    tokens = [token.strip() for token in seg_str.strip(' |').split('|')]\n    # 过滤空字符串\n    tokens = [token for token in tokens if token]\n    return tokens\n# 2. 解析真实分词和预测分词\nreal_tokens = parse_segmentation_string(real_str)\npredicted_tokens = parse_segmentation_string(predicted_str)\n# 3. 计算边界匹配\n# 将分词转换为字符边界位置\ndef get_boundaries(tokens):\n    boundaries = []\n    position = 0\n    for token in tokens:\n        boundaries.append((position, position + len(token)))\n        position += len(token)\n    return boundaries\nreal_boundaries = get_boundaries(real_tokens)\npred_boundaries = get_boundaries(predicted_tokens)\n# 4. 计算精确率、召回率、F1\nreal_set = set(real_boundaries)\npred_set = set(pred_boundaries)\ncorrect = len(real_set & pred_set)  # 正确边界数\npredicted_total = len(pred_set)  # 预测边界总数\nreal_total = len(real_set)  # 真实边界总数\nprecision = correct / predicted_total if predicted_total > 0 else 0\nrecall = correct / real_total if real_total > 0 else 0\nf1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n# 5. 错误分析\nerrors = {\n    'over_segmentation': [],  # 过切分（预测切分比真实更细）\n    'under_segmentation': [],  # 欠切分（预测切分比真实更粗）\n    'boundary_shift': []  # 边界偏移\n}\n# 详细错误分析\nfor pred_start, pred_end in pred_set:\n    if (pred_start, pred_end) not in real_set:\n        # 这是一个错误边界，需要分类\n        is_over = False\n        is_under = False\n        # 检查是否过切分（预测边界落在真实词内部）\n        for real_start, real_end in real_set:\n            if pred_start > real_start and pred_end < real_end:\n                is_over = True\n                errors['over_segmentation'].append({\n                    'predicted': predicted_tokens[pred_boundaries.index((pred_start, pred_end))],\n                    'position': pred_start,\n                    'containing_real_word': ''.join(real_tokens)\n                })\n                break\n        # 检查是否欠切分（预测边界跨越多个真实词）\n        if not is_over:\n            for real_start, real_end in real_set:\n                if pred_start < real_start and pred_end > real_end:\n                    is_under = True\n                    errors['under_segmentation'].append({\n                        'predicted': predicted_tokens[pred_boundaries.index((pred_start, pred_end))],\n                        'position': pred_start,\n                        'combined_real_words': real_tokens\n                    })\n                    break\n        # 边界偏移\n        if not is_over and not is_under:\n            errors['boundary_shift'].append({\n                'predicted': predicted_tokens[pred_boundaries.index((pred_start, pred_end))],\n                'position': pred_start\n            })\n# 6. 返回结果\n__result__= {\n    'metrics': {\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'correct_boundaries': correct,\n        'predicted_boundaries': predicted_total,\n        'real_boundaries': real_total\n    },\n    'error_analysis': errors,\n    'summary': {\n        'is_perfect_match': correct == real_total == predicted_total,\n        'token_count_difference': len(predicted_tokens) - len(real_tokens),\n        'error_count': predicted_total - correct\n    }\n}"
}